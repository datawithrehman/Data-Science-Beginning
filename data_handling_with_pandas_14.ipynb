{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "09b2c116",
   "metadata": {},
   "source": [
    "\n",
    "# üìä Read & Export Data Like a Pro with Pandas\n",
    "\n",
    "**Hook:** Dealing with CSVs or Excel? Here‚Äôs how to read, clean, and save your data with pandas ‚Äî no tech headache involved. üöÄ\n",
    "\n",
    "This notebook will guide you through the essential steps of data handling using the powerful pandas library in Python. From loading your data to cleaning it and finally exporting it, we'll cover everything you need to know to become a data pro!\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c690e7e6",
   "metadata": {},
   "source": [
    "---\n",
    "## üìò Author Information\n",
    "\n",
    "**üë®‚Äçüíª Name:** Abdul Rehman  \n",
    "**üìå Role:** Data Science Enthusiast | Python Learner  \n",
    "**üìÖ Notebook Created:** July 2025  \n",
    "\n",
    "**üîó Connect with Me:**  \n",
    "\n",
    "\n",
    "[![LinkedIn](https://img.shields.io/badge/LinkedIn-blue?style=flat&logo=linkedin&logoColor=white)](https://www.linkedin.com/in/abdul-rehman-74b418350/)\n",
    "[![GitHub](https://img.shields.io/badge/GitHub-black?style=flat&logo=github&logoColor=white)](https://github.com/datawithrehman/Data-Science-Beginning)\n",
    "[![Twitter](https://img.shields.io/badge/Twitter-blue?style=flat&logo=twitter&logoColor=white)](https://x.com/datawithrehman)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df135510",
   "metadata": {},
   "source": [
    "\n",
    "## üì• Reading Files: CSV and Excel\n",
    "\n",
    "The first step in any data analysis workflow is to load your data. Pandas provides intuitive functions to read various file formats, including CSV (Comma Separated Values) and Excel files.\n",
    "\n",
    "- `pd.read_csv()`: For reading data from CSV files.\n",
    "- `pd.read_excel()`: For reading data from Excel files.\n",
    "\n",
    "Let's see how it works!\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33641445",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import pandas as pd\n",
    "\n",
    "# Create dummy CSV and Excel files for demonstration\n",
    "# In a real scenario, you would replace these with your actual file paths.\n",
    "\n",
    "dummy_data_csv = {\n",
    "    'Name': ['Alice', 'Bob', 'Charlie', 'David', 'Eve'],\n",
    "    'Age': [24, 27, 22, 32, 29],\n",
    "    'City': ['New York', 'Los Angeles', 'Chicago', 'Houston', 'Phoenix']\n",
    "}\n",
    "df_dummy_csv = pd.DataFrame(dummy_data_csv)\n",
    "df_dummy_csv.to_csv('dummy_data.csv', index=False)\n",
    "\n",
    "dummy_data_excel = {\n",
    "    'Product': ['Laptop', 'Mouse', 'Keyboard', 'Monitor', 'Webcam'],\n",
    "    'Price': [1200, 25, 75, 300, 50],\n",
    "    'Quantity': [10, 50, 30, 5, 20]\n",
    "}\n",
    "df_dummy_excel = pd.DataFrame(dummy_data_excel)\n",
    "df_dummy_excel.to_excel('dummy_data.xlsx', index=False)\n",
    "\n",
    "print(\"Dummy 'dummy_data.csv' created.\")\n",
    "print(\"Dummy 'dummy_data.xlsx' created.\")\n",
    "\n",
    "# Now, let's read these files using pandas\n",
    "\n",
    "try:\n",
    "    df_csv = pd.read_csv('dummy_data.csv')\n",
    "    print(\"\n",
    "Successfully read 'dummy_data.csv':\")\n",
    "    print(df_csv.head())\n",
    "except FileNotFoundError:\n",
    "    print(\"Error: 'dummy_data.csv' not found. Please ensure the file exists.\")\n",
    "\n",
    "try:\n",
    "    df_excel = pd.read_excel('dummy_data.xlsx')\n",
    "    print(\"\n",
    "Successfully read 'dummy_data.xlsx':\")\n",
    "    print(df_excel.head())\n",
    "except FileNotFoundError:\n",
    "    print(\"Error: 'dummy_data.xlsx' not found. Please ensure the file exists.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d468cb7",
   "metadata": {},
   "source": [
    "\n",
    "## üîç Previewing Your Data\n",
    "\n",
    "After loading your data, it's crucial to get a quick overview of its structure and content. Pandas DataFrames offer several methods for this:\n",
    "\n",
    "- `.head()`: Displays the first 5 rows of the DataFrame (or a specified number).\n",
    "- `.info()`: Provides a concise summary of the DataFrame, including data types, non-null values, and memory usage.\n",
    "- `.shape`: Returns a tuple representing the dimensions of the DataFrame (rows, columns).\n",
    "\n",
    "Let's inspect our loaded dataframes.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1554b9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "print(\"\n",
    "--- Previewing df_csv ---\")\n",
    "print(df_csv.head())\n",
    "print(\"\n",
    "\")\n",
    "print(df_csv.info())\n",
    "print(\"\n",
    "Shape of df_csv:\", df_csv.shape)\n",
    "\n",
    "print(\"\n",
    "--- Previewing df_excel ---\")\n",
    "print(df_excel.head())\n",
    "print(\"\n",
    "\")\n",
    "print(df_excel.info())\n",
    "print(\"\n",
    "Shape of df_excel:\", df_excel.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d3cc706",
   "metadata": {},
   "source": [
    "\n",
    "## üéØ Selecting Columns During Import\n",
    "\n",
    "Sometimes, you only need a subset of columns from a large dataset. Importing only the necessary columns can save memory and speed up your data loading process. You can achieve this using the `usecols` parameter in `read_csv()` and `read_excel()`.\n",
    "\n",
    "This is especially useful for very wide datasets where you're only interested in a few specific features.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d51940fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Let's say we only need 'Name' and 'City' from our dummy_data.csv\n",
    "df_selected_cols = pd.read_csv('dummy_data.csv', usecols=['Name', 'City'])\n",
    "\n",
    "print(\"\n",
    "DataFrame with selected columns ('Name', 'City'):\")\n",
    "print(df_selected_cols.head())\n",
    "\n",
    "# You can also select columns by their integer position (0-indexed)\n",
    "# For example, to select the first two columns (Name and Age)\n",
    "df_selected_by_pos = pd.read_csv('dummy_data.csv', usecols=[0, 1])\n",
    "\n",
    "print(\"\n",
    "DataFrame with selected columns by position (0, 1):\")\n",
    "print(df_selected_by_pos.head())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92ff4fb0",
   "metadata": {},
   "source": [
    "\n",
    "## ‚ú® Cleaning Data: Handling Missing Values\n",
    "\n",
    "Real-world data is often messy and contains missing values (represented as `NaN` - Not a Number in pandas). Handling these missing values is a crucial step in data cleaning. A common approach is to remove rows or columns that contain `NaN` values using the `.dropna()` method.\n",
    "\n",
    "**Important Note:** Dropping missing values should be done carefully, as it can lead to loss of valuable data. For this beginner-friendly notebook, we'll use a simple `dropna()` for demonstration. In more advanced scenarios, you might consider imputation (filling missing values with estimated ones).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02482bcc",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Let's create a dummy DataFrame with some missing values\n",
    "data_with_nulls = {\n",
    "    'Student_ID': [1, 2, 3, 4, 5],\n",
    "    'Math_Score': [85, 92, None, 78, 95],\n",
    "    'Science_Score': [70, None, 88, 91, 80],\n",
    "    'English_Score': [90, 85, 75, None, 92]\n",
    "}\n",
    "df_marks = pd.DataFrame(data_with_nulls)\n",
    "\n",
    "print(\"\n",
    "Original DataFrame with missing values:\")\n",
    "print(df_marks)\n",
    "\n",
    "# Clean nulls: Drop rows with any missing values\n",
    "df_cleaned_marks = df_marks.dropna()\n",
    "\n",
    "print(\"\n",
    "DataFrame after dropping rows with null values:\")\n",
    "print(df_cleaned_marks)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04a7f170",
   "metadata": {},
   "source": [
    "\n",
    "## üíæ Saving Files: Exporting Your Cleaned Data\n",
    "\n",
    "Once you've processed and cleaned your data, you'll want to save it for future use or sharing. Pandas provides `.to_csv()` and `.to_excel()` methods for exporting DataFrames.\n",
    "\n",
    "- `.to_csv()`: Exports the DataFrame to a CSV file.\n",
    "- `.to_excel()`: Exports the DataFrame to an Excel file.\n",
    "\n",
    "### üö® Mistake Alert: Unintended Index Column!\n",
    "\n",
    "A common pitfall when saving to CSV is including the DataFrame index as a new column. By default, `to_csv()` includes the index. To prevent this, **always use `index=False`**.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ca4bb8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Save the cleaned student marks to a CSV file\n",
    "# INCORRECT WAY (will include index column)\n",
    "df_cleaned_marks.to_csv('student_marks_cleaned_with_index.csv')\n",
    "print(\"Saved 'student_marks_cleaned_with_index.csv' (check this file to see the extra index column).\")\n",
    "\n",
    "# CORRECT WAY (without index column)\n",
    "df_cleaned_marks.to_csv('student_marks_cleaned_no_index.csv', index=False)\n",
    "print(\"Saved 'student_marks_cleaned_no_index.csv' (this is the recommended way!).\")\n",
    "\n",
    "# You can also save to Excel\n",
    "df_cleaned_marks.to_excel('student_marks_cleaned.xlsx', index=False)\n",
    "print(\"Saved 'student_marks_cleaned.xlsx'.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7141462",
   "metadata": {},
   "source": [
    "\n",
    "## üèÜ Mini Challenge\n",
    "\n",
    "Put your new skills to the test! Your challenge is to:\n",
    "\n",
    "1.  Load a CSV file (you can use `dummy_data.csv` or create your own).\n",
    "2.  Introduce some null values if your data doesn't have any (optional, for practice).\n",
    "3.  Clean the null values using `dropna()`.\n",
    "4.  Save the cleaned data to a new CSV file, ensuring you use `index=False`.\n",
    "\n",
    "Feel free to modify the `dummy_data.csv` or create a new one to experiment!\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a9f7690",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Your code for the Mini Challenge goes here!\n",
    "# Example (you can uncomment and run this, or write your own):\n",
    "\n",
    "# df_challenge = pd.read_csv('dummy_data.csv')\n",
    "# # Optional: Introduce a null value for demonstration\n",
    "# # df_challenge.loc[0, 'Age'] = None\n",
    "# print(\"\n",
    "Challenge: Original DataFrame (potentially with new nulls):\")\n",
    "# print(df_challenge)\n",
    "\n",
    "# df_challenge_cleaned = df_challenge.dropna()\n",
    "# print(\"\n",
    "Challenge: Cleaned DataFrame:\")\n",
    "# print(df_challenge_cleaned)\n",
    "\n",
    "# df_challenge_cleaned.to_csv('challenge_output.csv', index=False)\n",
    "# print(\"\n",
    "Challenge: Saved 'challenge_output.csv' with index=False.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61e28e36",
   "metadata": {},
   "source": [
    "\n",
    "## üéâ Conclusion\n",
    "\n",
    "Congratulations! You've successfully learned how to read, preview, clean, and export data using pandas. These are fundamental skills for any data professional.\n",
    "\n",
    "Remember the `index=False` trick when saving CSVs to keep your data clean and avoid unexpected columns.\n",
    "\n",
    "Happy data wrangling! üöÄ\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
